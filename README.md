# Dual-Path Lambda Learning  
### Functional Adaptive Convergence via Drift Minimization and Gain Control

This repository implements a **minimal functional learning system** that compares two fundamentally different optimization dynamics:

‚Ä¢ Standard gradient drift minimization  
‚Ä¢ Adaptive gain-controlled learning with internal sensitivity decay  

The system is built entirely from **immutable lambda-style state transitions**, turning learning into a clean dynamical process rather than imperative parameter mutation.

Convergence is evaluated using **information-theoretic drift (KL divergence)** alongside prediction error.


---

## üîç Core Concept

Learning is modeled as a deterministic state machine:

Each update step:

1. Observes noisy data sampled from a true underlying distribution  
2. Computes an error signal relative to the current internal belief  
3. Applies pure functional transitions to produce the next state  

Two learning pathways operate in parallel:

### Path A ‚Äî Drift Minimization

A classic gradient descent dynamic that directly adjusts the internal representation toward observed data.

### Path B ‚Äî Adaptive Gain Control

A coupled system where:

‚Ä¢ The representation is updated  
‚Ä¢ A sensitivity (gain) parameter scales learning intensity  
‚Ä¢ The gain decays over time, stabilizing convergence  

### Notes

‚Ä¢ Path A is the explorer, and Path B is the map-maker.

‚Ä¢ Path B represents adaptive learning, while Path A demonstrates why naive gradient drift fails in noisy environments.

‚Ä¢ This creates a self-regulating learning process.

‚Ä¢ Information requires a carrier. Path A is the carrier (the signal), and Path B is the information (the meaning/stability extracted from that signal).

---

## üß† Functional Architecture

All learning behavior is expressed as stateless transformations:

‚Ä¢ No in-place parameter mutation  
‚Ä¢ No optimizer objects  
‚Ä¢ No hidden side effects  

State evolution is entirely driven by composable transition functions.

This mirrors functional dynamical systems used in theoretical ML and neuromorphic models.

---

## üìä What Is Measured

At every step the system tracks:

‚Ä¢ Information drift between learned and true distributions  
‚Ä¢ Prediction error on sampled data  
‚Ä¢ Internal gain dynamics  

This directly measures **how accurately the model infers reality**, not just loss reduction.

---

## üî¨ Key Experimental Observations

Across runs, adaptive gain control consistently:

‚úÖ Converges faster  
‚úÖ Produces smoother learning curves  
‚úÖ Resists noise-induced oscillations  
‚úÖ Stabilizes long-term inference  

While drift-only learning overshoots and fluctuates under noise.

---

## üß™ Main Takeaways

### 1. Learning benefits from internal control dynamics

Coupling representation updates with a self-regulating sensitivity parameter dramatically improves stability.

---

### 2. Adaptive behavior emerges from simple rules

Second-order style optimization effects arise without complex math or heavy algorithms.

---

### 3. Information convergence matters more than loss alone

The system does not just minimize error ‚Äî it actively aligns inferred structure with ground truth.

---

### 4. Functional state transitions are sufficient for learning systems

Complex learning behavior can emerge from pure transformations.

---

## üéØ Scientific Relevance

This project connects ideas from:

‚Ä¢ Variational inference  
‚Ä¢ Predictive coding  
‚Ä¢ Adaptive optimization  
‚Ä¢ Control-theoretic learning  
‚Ä¢ Functional programming models of computation  

In a minimal, interpretable simulation.

---

## üìà Visualization

A real-time GUI displays:

‚Ä¢ Information drift comparison  
‚Ä¢ Prediction error trajectories  
‚Ä¢ Gain parameter decay  

Allowing intuitive inspection of learning dynamics.

## Conclusion

This project demonstrates that a deterministic, fixed-point adaptive learning system can track a target mean under noisy inputs while simultaneously monitoring real-time certainty using Fisher information.

Key takeaways:

Deterministic belief updates: The lambda-calculus-based update rule reliably converges to the true mean.

Certainty tracking: Fisher information grows with each observation, showing confidence growing over time. 


